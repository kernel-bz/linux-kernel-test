
//CPU topology

drivers/base/arch_topology.c
parse_dt_topology()

//include/linux/arch_topology.h
struct cpu_topology {
        int thread_id;
        int core_id;
        int package_id;
        int llc_id;
        cpumask_t thread_sibling;
        cpumask_t core_sibling;
        cpumask_t llc_sibling;
};

drivers/base/arch_topology.c
parse_core()

//device-tree node
/cpus
  cpu-map
    cluster#
      core#
        thread#

kernel_init_freeable()
  smp_prepare_cpus()
    init_cpu_topology()	//device tree
  smp_init()
    cpu_up(cpu)
  sched_init_smp()
    sched_init_numa()
    sched_init_domains()

//arch/*/kernel/topology.c
store_cpu_topology()

include/linux/cpuhotplug.h

include/linux/sched/topology.h
#define SD_LOAD_BALANCE		0x0001	/* Do load balancing on this domain. */
#define SD_BALANCE_NEWIDLE	0x0002	/* Balance when about to become idle */
#define SD_BALANCE_EXEC		0x0004	/* Balance on exec */
#define SD_BALANCE_FORK		0x0008	/* Balance on fork, clone */
#define SD_BALANCE_WAKE		0x0010  /* Balance on wakeup */
#define SD_WAKE_AFFINE		0x0020	/* Wake task to waking CPU */
#define SD_ASYM_CPUCAPACITY	0x0040  /* Domain members have different CPU capacities */
#define SD_SHARE_CPUCAPACITY	0x0080	/* Domain members share CPU capacity */
#define SD_SHARE_POWERDOMAIN	0x0100	/* Domain members share power domain */
#define SD_SHARE_PKG_RESOURCES	0x0200	/* Domain members share CPU pkg resources */
#define SD_SERIALIZE		0x0400	/* Only a single load balancing instance */
#define SD_ASYM_PACKING		0x0800  /* Place busy groups earlier in the domain */
#define SD_PREFER_SIBLING	0x1000	/* Prefer to place tasks in a sibling domain */
#define SD_OVERLAP		0x2000	/* sched_domains of this level overlap */
#define SD_NUMA			0x4000	/* cross-node balancing */


kernel/sched/topology.c
sched_init_numa()

include/linux/sched/topology.h
struct sd_data {
        struct sched_domain *__percpu *sd;
        struct sched_domain_shared *__percpu *sds;
        struct sched_group *__percpu *sg;
        struct sched_group_capacity *__percpu *sgc;
};

struct sched_domain_topology_level {
    sched_domain_mask_f 	mask;
    sched_domain_flags_f 	sd_flags;
    int		    		flags;
    int		    		numa_level;
    struct sd_data      	data;
    char                	*name;
};

struct sched_domain_shared {
        atomic_t	ref;
        atomic_t	nr_busy_cpus;
        int		has_idle_cores;
};

struct sched_domain {
        struct sched_domain __rcu *parent;	/* top domain must be null terminated */
        struct sched_domain __rcu *child;	/* bottom domain must be null terminated */
        struct sched_group *groups;	/* the balancing groups of the domain */
        unsigned long min_interval;	/* Minimum balance interval ms */
        unsigned long max_interval;	/* Maximum balance interval ms */
        unsigned int busy_factor;	/* less balancing by factor if busy */
        unsigned int imbalance_pct;	/* No balance until over watermark */
        unsigned int cache_nice_tries;	/* Leave cache hot tasks for # tries */

        int nohz_idle;			/* NOHZ IDLE status */
        int flags;			/* See SD_* */
        int level;
        //...
}


//kernel/sched/sched.h
struct sched_group {
        struct sched_group	*next;
        atomic_t		ref;
        unsigned int		group_weight;
        struct sched_group_capacity *sgc;
        int			asym_prefer_cpu;
        unsigned long		cpumask[0];
};

struct sched_group_capacity {
        atomic_t		ref;
        unsigned long		capacity;
        unsigned long		min_capacity;
        unsigned long		max_capacity;
        unsigned long		next_update;
        int			imbalance;
        int			id;
        unsigned long		cpumask[0];
};

//kernel/sched/topology.c
struct s_data {
        struct sched_domain * __percpu *sd;
        struct root_domain	*rd;
};

//kernel/sched/sched.h
struct root_domain {
        atomic_t		refcount;
        atomic_t		rto_count;
        struct rcu_head		rcu;
        cpumask_var_t		span;
        cpumask_var_t		online;

        int			overload;
        int			overutilized;

        cpumask_var_t		dlo_mask;
        atomic_t		dlo_count;
        struct dl_bw		dl_bw;
        struct cpudl		cpudl;
}
